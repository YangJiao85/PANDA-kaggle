{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "panda-png-kfold.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YangJiao85/PANDA-kaggle/blob/master/panda_png_kfold_1epoch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkzZTOPO-qRC",
        "colab_type": "text"
      },
      "source": [
        "# PANDA: start from tiles in png zip file and evaluate using KFold cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew7punje-qRE",
        "colab_type": "text"
      },
      "source": [
        "This notebook got inspirations from\n",
        "- [PANDA 16X128X128 tiles from Iafoss](https://www.kaggle.com/iafoss/panda-16x128x128-tiles) \n",
        "\n",
        "Thank you for sharing!\n",
        "\n",
        "This note book extracts tiles from original images and save them as dataset panda-tile-ntxnrxnr."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lY5sU_59cSQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8034f4f2-1a86-4153-d851-d2d26f57a25f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWAomNrG-qRG",
        "colab_type": "text"
      },
      "source": [
        "Set some parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6q5ZX1m-qRH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" PATH on kaggle\n",
        "DATA_PATH     = '/kaggle/input/prostate-cancer-grade-assessment/'\n",
        "TRAIN_PATH    = DATA_PATH + 'train_images/'\n",
        "MASKS_PATH    = DATA_PATH + 'train_label_masks/'\n",
        "TEST_PATH     = DATA_PATH + 'test_images/'\n",
        "PP_PATH       = '/kaggle/input/panda-tiles/'\n",
        "TRAIN_TILES_PATH = PP_PATH + 'train_images_tiles16x128x128/'\n",
        "MASKS_TILES_PATH = PP_PATH + 'train_masks_tiles16x128x128/'\n",
        "MODEL_PATH    = './'                                       # path to save model\n",
        "ENET_MODEL_PATH = '/kaggle/input/efficientnettf/'          # pretrained model from efficientnet package\n",
        "restart_path  = '/kaggle/input/panda-tiles-tf-keras-cohen-kappa-loss-baseline/model_v1.1.h5'\n",
        "ZIP_TRAIN     = TRAIN_TILES_PATH + 'train.zip'                # zip file with tiled images\n",
        "ZIP_MASKS     = MASKS_TILES_PATH + 'masks.zip'                # zip file with tiled masks\n",
        "\"\"\"\n",
        "\"\"\" PATH on Colab \"\"\"\n",
        "Colab_ROOT    = '/content/drive/My Drive/Colab Notebooks/competetions/'\n",
        "DATA_PATH     = Colab_ROOT + 'input/prostate-cancer-grade-assessment/'\n",
        "TRAIN_PATH    = DATA_PATH + 'train_images/'\n",
        "MASKS_PATH    = DATA_PATH + 'train_label_masks/'\n",
        "TEST_PATH     = DATA_PATH + 'test_images/'\n",
        "TRAIN_TILES_PATH = DATA_PATH + 'train_images_tiles16x128x128/'\n",
        "MASKS_TILES_PATH = DATA_PATH + 'train_masks_tiles16x128x128/'\n",
        "MODEL_PATH    = Colab_ROOT + 'PANDA/'                         # path to save model\n",
        "ENET_MODEL_PATH = './'                                        # pretrained model from efficientnet package\n",
        "restart_path  = MODEL_PATH + 'model_v1.1.h5'\n",
        "ZIP_TRAIN     = TRAIN_TILES_PATH + 'train.zip'                # zip file with tiled images\n",
        "ZIP_MASKS     = MASKS_TILES_PATH + 'masks.zip'                # zip file with tiled masks\n",
        "\n",
        "\n",
        "MODEL_VERSION = 'v1.2'                                     # version for the model to be saved\n",
        "restart       = True\n",
        "EPOCHS        = 1\n",
        "TILE_SIZE     = 128      # 16 128x128 tiles are selected from each image and mask\n",
        "NUM_TILE      = 16\n",
        "BATCH_SIZE    = 4\n",
        "INI_LR        = 1.e-4\n",
        "\n",
        "SEED          = 2020\n",
        "N_FOLD        = 4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3MlflaR-qRM",
        "colab_type": "text"
      },
      "source": [
        "Update to TensorFlow 2.2.0 and TensorFlow-Addons 0.10.0.\n",
        "- CohenKappa metric and WeightedKappaLoose are used as implemented in TensorFlow Addons 0.10.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3iWR56Y-qRN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0636b36d-d13e-4bbc-9dcb-bb3a8992fd71"
      },
      "source": [
        "import sys\n",
        "print('Python {}'.format(sys.version))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9 (default, Apr 18 2020, 01:56:04) \n",
            "[GCC 8.4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IhQGOeT-qRU",
        "colab_type": "text"
      },
      "source": [
        "Check TensorFlow and TensorFlow-Addons version."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qsbul5ibOY2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "99fb3731-c094-420d-f2a9-7da93ed3e717"
      },
      "source": [
        "\"\"\"\n",
        "%%time\n",
        "!pip install /kaggle/input/panda-pp/pygame-1.9.6-cp37-cp37m-manylinux1_x86_64.whl\n",
        "!pip install --quiet /kaggle/input/keras-applications/Keras_Applications-1.0.8-py3-none-any.whl\n",
        "!pip install --quiet /kaggle/input/efficientnetrepo110/efficientnet-1.1.0-py3-none-any.whl\n",
        "\"\"\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\n%%time\\n!pip install /kaggle/input/panda-pp/pygame-1.9.6-cp37-cp37m-manylinux1_x86_64.whl\\n!pip install --quiet /kaggle/input/keras-applications/Keras_Applications-1.0.8-py3-none-any.whl\\n!pip install --quiet /kaggle/input/efficientnetrepo110/efficientnet-1.1.0-py3-none-any.whl\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-0H52k8ciyM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "11f235d3-8eeb-4729-9c78-8404297ad0fc"
      },
      "source": [
        "%%time\n",
        "!pip install --quiet efficientnet\n",
        "!pip install --quiet pygame\n",
        "!pip install --quiet memory_profiler\n",
        "!pip install --quiet tensorflow-addons==0.10.0"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 53.3 ms, sys: 23.9 ms, total: 77.2 ms\n",
            "Wall time: 13.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWdFh8KE-qRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fefb9b8f-0164-4026-c114-72267b2173f9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "print('TensorFlow version:        {}'.format(tf.__version__))\n",
        "print('TensorFlow-Addons version: {}'.format(tfa.__version__))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:        2.2.0\n",
            "TensorFlow-Addons version: 0.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqm2Aoks-qRY",
        "colab_type": "text"
      },
      "source": [
        "Load essential modules. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "1LZrZGeR-qRY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8baa880c-d120-415f-ffa4-bd3c1e08c460"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow.keras as K\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import albumentations as albu      # a fast image augmentation library\n",
        "\n",
        "import skimage.io\n",
        "import json\n",
        "\n",
        "from tensorflow.keras import Model, Sequential\n",
        "import efficientnet.tfkeras as efn\n",
        "\n",
        "import os\n",
        "import memory_profiler\n",
        "import time\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "from tqdm.notebook import tqdm    # A Fast, Extensible Progress Bar \n",
        "                                  # for Python and CLI \n",
        "import cv2\n",
        "import binascii\n",
        "import io\n",
        "import pygame                     # a Python wrapper module for the SDL multimedia library"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pygame 1.9.6\n",
            "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEKLkxNx-qRb",
        "colab_type": "text"
      },
      "source": [
        "Check GPUs availability. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb6KHkDa-qRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5cb3dade-5773-42de-daf0-28fbe2ba45cd"
      },
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print('{} Physical GPUs, {} Logical GPUs'.format(len(gpus), len(logical_gpus)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FTVYmHoOmHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c7c521f-7f29-4fb0-ef10-9cf2d9d8c313"
      },
      "source": [
        "cpus = tf.config.list_physical_devices('CPU')\n",
        "if cpus:\n",
        "    logical_cpus = tf.config.list_logical_devices('CPU')\n",
        "    print('{} Physical CPUs, {} Logical CPUs'.format(len(cpus), len(logical_cpus)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical CPUs, 1 Logical CPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhgxDeUAMslS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_start = time.time()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lP-YDNy-qRg",
        "colab_type": "text"
      },
      "source": [
        "## Tiles of image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef1YTHyU-qRg",
        "colab_type": "text"
      },
      "source": [
        "Load whole slide image(WSI), and select 16 128x128 tiles from each image according to the number of tissure pixels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7p4E2m_-qRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tile(img_id, mode = 'train', mask = False, tile_size = 128, num_tile = 16, aug = None):\n",
        "    # This function selects <num_tile> tiles of size <tile_size>x<tile_size> \n",
        "    # for image of <img_id> (and mask) \n",
        "    # based on the maximum number of tissue pixels.\n",
        "    if(mode == 'train'):\n",
        "        img = skimage.io.MultiImage(os.path.join(TRAIN_PATH, img_id + '.tiff'))[-1] \n",
        "    elif(mode == 'test'):\n",
        "        img = skimage.io.MultiImage(os.path.join(TEST_PATH, img_id + '.tiff'))[-1]\n",
        "    else:\n",
        "        raise AttributeError('tile mode Error')\n",
        "    if aug:\n",
        "        img = aug(image=img)['image']\n",
        "    shape = img.shape\n",
        "    pad0, pad1 = (tile_size - shape[0]%tile_size)%tile_size, (tile_size - shape[1]%tile_size)%tile_size\n",
        "    img = np.pad(img, [[pad0//2, pad0-pad0//2], [pad1//2, pad1-pad1//2], [0,0]],\n",
        "                 constant_values = 255)\n",
        "    img = img.reshape(img.shape[0]//tile_size, tile_size, img.shape[1]//tile_size, tile_size,3)\n",
        "    img = img.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size, 3)\n",
        "    if len(img) < num_tile:\n",
        "        img = np.pad(img, [[0, num_tile - len(img)], [0, 0], [0, 0], [0, 0]], \n",
        "                     constant_values = 255)    \n",
        "    idxs = np.argsort(img.reshape(img.shape[0], -1).sum(-1))[:num_tile]\n",
        "    img = np.array(img[idxs])\n",
        "    \n",
        "    if(mask):\n",
        "        mask = skimage.io.MultiImage(os.path.join(MASKS_PATH, img_id + '_mask.tiff'))[-1]\n",
        "        if aug: \n",
        "            mask = aug(image=mask)['image']\n",
        "        if(mask.shape != shape):\n",
        "            print(f'ID {img_id} image shape {shape} mask shape {mask.shape}')\n",
        "            mask = np.zeros_like(img)\n",
        "            return img, mask\n",
        "        mask = np.pad(mask, [[pad0//2, pad0-pad0//2], [pad1//2, pad1-pad1//2], [0,0]],\n",
        "                      constant_values = 0)\n",
        "        mask = mask.reshape(mask.shape[0]//tile_size, tile_size, mask.shape[1]//tile_size, tile_size,3)\n",
        "        mask = mask.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size, 3)\n",
        "        if len(mask) < num_tile:\n",
        "            mask = np.pad(mask, [[0, num_tile - len(mask)], [0, 0], [0, 0], [0, 0]], \n",
        "                          constant_values = 0)\n",
        "        mask = np.array(mask[idxs])\n",
        "        return img, mask\n",
        "    else:\n",
        "        return img\n",
        "    \n",
        "def glue_to_one(tile_seq):\n",
        "    l_tile = int(math.sqrt(NUM_TILE))\n",
        "    img_glue = np.zeros((l_tile*TILE_SIZE, l_tile*TILE_SIZE, 3),\n",
        "                         dtype = np.float32)\n",
        "    for i, t in enumerate(tile_seq):\n",
        "        x = i//l_tile\n",
        "        y = i%l_tile\n",
        "        img_glue[x*TILE_SIZE:(x+1)*TILE_SIZE,\n",
        "                 y*TILE_SIZE:(y+1)*TILE_SIZE, :] = t\n",
        "    return img_glue"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_c8rSJN-qRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PANDA_Sequence(Sequence):\n",
        "    def __init__(self, df, batch_size=16, mode='fit', shuffle = False, aug = None, \n",
        "                 num_tile = 16, tile_size = 128, n_classes=6):\n",
        "        self.df = df            # data frame with the image_id\n",
        "        self.batch_size = batch_size\n",
        "        self.mode = mode\n",
        "        self.shuffle = shuffle\n",
        "        self.aug = aug\n",
        "        self.tile_size = tile_size\n",
        "        self.num_tile = num_tile\n",
        "        self.n_classes = n_classes\n",
        "        self.l_tile = int(math.sqrt(self.num_tile))\n",
        "        if(self.mode == 'fit'):\n",
        "            self.tile_mode = 'train'\n",
        "            self.tile_mask = False\n",
        "        elif(self.mode == 'validate'):\n",
        "            self.tile_mode = 'train'\n",
        "            self.tile_mask = False\n",
        "        elif(self.mode == 'predict'):\n",
        "            self.tile_mode = 'test'\n",
        "            self.tile_mask = False\n",
        "        else:\n",
        "            raise AttributeError('Sequence mode Error')\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        return math.floor(len(self.df) / self.batch_size)\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    def __getitem__(self, index):\n",
        "        X = np.zeros((self.batch_size, self.l_tile*self.tile_size, self.l_tile*self.tile_size, 3), dtype = np.float32)\n",
        "        img_batch = self.df[index*self.batch_size : (index+1)*self.batch_size]['image_id'].values\n",
        "        for i, img_id in enumerate(img_batch):\n",
        "            img_tiles = tile(img_id, mode = self.tile_mode, mask = self.tile_mask, tile_size = self.tile_size,\n",
        "                             num_tile = self.num_tile, aug = self.aug)\n",
        "            X[i,] = glue_to_one(img_tiles)/255.\n",
        "        if self.mode in ['fit', 'validate']:\n",
        "            y = np.zeros((self.batch_size, self.n_classes), dtype = np.float32)\n",
        "            # encode label list\n",
        "            lbls_batch = self.df[index * self.batch_size: (index+1) * self.batch_size]['isup_grade'].values\n",
        "            for i in range(self.batch_size):\n",
        "                y[i, lbls_batch[i]] = 1\n",
        "            return X, y\n",
        "        elif self.mode == 'predict':\n",
        "            return X\n",
        "        else:\n",
        "            raise AttributeError('mode parameter error')        "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8jFvgnRhdx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PANDA_tile_Sequence(Sequence):\n",
        "    def __init__(self, df, batch_size=16, mode='fit', shuffle = False, aug = None, \n",
        "                 num_tile = 16, tile_size = 128, n_classes=6):\n",
        "        self.df = df            # data frame with the image_id\n",
        "        self.batch_size = batch_size\n",
        "        self.mode = mode\n",
        "        self.shuffle = shuffle\n",
        "        self.aug = aug\n",
        "        self.tile_size = tile_size\n",
        "        self.num_tile = num_tile\n",
        "        self.n_classes = n_classes\n",
        "        self.l_tile = int(math.sqrt(self.num_tile))\n",
        "        if(self.mode == 'fit'):\n",
        "            self.tile_mode = 'train'\n",
        "            self.tile_mask = False\n",
        "        elif(self.mode == 'validate'):\n",
        "            self.tile_mode = 'train'\n",
        "            self.tile_mask = False\n",
        "        elif(self.mode == 'predict'):\n",
        "            self.tile_mode = 'test'\n",
        "            self.tile_mask = False\n",
        "        else:\n",
        "            raise AttributeError('Sequence mode Error')\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        return math.floor(len(self.df) / self.batch_size)\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "    def __getitem__(self, index):\n",
        "        X = np.zeros((self.batch_size, self.l_tile*self.tile_size, self.l_tile*self.tile_size, 3), dtype = np.float32)\n",
        "        img_batch = self.df[index*self.batch_size : (index+1)*self.batch_size]['image_id'].values\n",
        "        if self.tile_mode == 'train':\n",
        "            archive_img = zipfile.ZipFile(ZIP_TRAIN, 'r')\n",
        "            for i, img_id in enumerate(img_batch):\n",
        "                data_img = archive_img.read(img_id + '_tiles.png')\n",
        "                bytes_io = io.BytesIO(data_img)\n",
        "                img_tiles = pygame.image.load(bytes_io)\n",
        "                X[i,] = pygame.surfarray.array3d(img_tiles)/255.\n",
        "        else:\n",
        "            for i, img_id in enumerate(img_batch):\n",
        "                img_tiles = tile(img_id, mode = self.tile_mode, mask = self.tile_mask, tile_size = self.tile_size,\n",
        "                                 num_tile = self.num_tile, aug = self.aug)\n",
        "                X[i,] = glue_to_one(img_tiles)/255.\n",
        "        if self.mode in ['fit', 'validate']:\n",
        "            y = np.zeros((self.batch_size, self.n_classes), dtype = np.float32)\n",
        "            # encode label list\n",
        "            lbls_batch = self.df[index * self.batch_size: (index+1) * self.batch_size]['isup_grade'].values\n",
        "            for i in range(self.batch_size):\n",
        "                y[i, lbls_batch[i]] = 1\n",
        "            return X, y\n",
        "        elif self.mode == 'predict':\n",
        "            return X\n",
        "        else:\n",
        "            raise AttributeError('mode parameter error')        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmZQS-NL-qRk",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyjOYQ50-qRk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "49928551-acab-4823-e444-c664687f61ee"
      },
      "source": [
        "print('Memory usage : {} MB'.format(*memory_profiler.memory_usage(-1)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage : 958.59765625 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB4kyG9z-qRn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad21389a-a0e4-45a6-c493-a8dc4226d656"
      },
      "source": [
        "df_train = pd.read_csv('{}/train.csv'.format(DATA_PATH))\n",
        "print('train: {}'.format(df_train.shape))\n",
        "print('unique isup grade: {}'.format(df_train['isup_grade'].nunique()))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: (10616, 4)\n",
            "unique isup grade: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH7BivQyhg9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa896fc3-9805-43f4-d403-4e8a1b981fea"
      },
      "source": [
        "img_mismatch_list =(\n",
        "        '0bc1fdd9a51cf38d3dffac3541189c02',\n",
        "        '0c0041c562f7cbcb69a4d195d5a06114',\n",
        "        '0e9219ba3378fbf1de1743a53f3a0c18',\n",
        "        '107694232cb071255848ddca5efbe061',\n",
        "        '184b98556b06d9962dee7e737b23902b',\n",
        "        '1abf1e5a8a5aef4100c97ffd8ea09ce4',\n",
        "        '35a01018982323a647399b88ef4d2287',\n",
        "        '5a4ec1ea101e790664aeab41d54cbe75',\n",
        "        '7df260d73a124534f81a62768190ba8b',\n",
        "        '852768d64622d6bb9e0d2c3ef45660f5',\n",
        "        'a38edfd7f0ab8eb00995e7c1c3168b60',\n",
        "        'a59b754e6ae29ba224e7422995ebb5fe',\n",
        "        'b7f0f181cd947530a0d7ecb9c35b992f',\n",
        "        'b8f8ccffefda42fbe46878921e9d1194',\n",
        "        'bb33e9befff93c6918e691486eed3990',\n",
        "        'c2265a32286d90695745e411d313b694'\n",
        ")\n",
        "keep_item = df_train['image_id'].apply(lambda x: x not in img_mismatch_list)\n",
        "df_train = df_train[keep_item]\n",
        "print('train: {}'.format(df_train.shape))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train: (10600, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50FV6_WhJ596",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the tiles png files\n",
        "def plot_tiles_png(img_id):\n",
        "    img = skimage.io.MultiImage(os.path.join(TRAIN_PATH, img_id + '.tiff'))[-1]\n",
        "    \n",
        "    archive_img = zipfile.ZipFile(ZIP_TRAIN, 'r')\n",
        "    data_img = archive_img.read(img_id + '_tiles.png')\n",
        "    bytes_io = io.BytesIO(data_img)\n",
        "    img_tiles = pygame.image.load(bytes_io)\n",
        "    img_tiles = pygame.surfarray.array3d(img_tiles)\n",
        "    print(img_tiles.shape)\n",
        "\n",
        "    archive_mask = zipfile.ZipFile(ZIP_MASKS, 'r')\n",
        "    data_mask = archive_mask.read(img_id + '_mask_tiles.png')\n",
        "    bytes_io = io.BytesIO(data_mask)\n",
        "    mask_tiles = pygame.image.load(bytes_io)\n",
        "    mask_tiles = pygame.surfarray.array2d(mask_tiles)\n",
        "    print(mask_tiles.shape)\n",
        "        \n",
        "    fig, ax = plt.subplots(1, 3, figsize=(18,12))\n",
        "    fig.suptitle('Image ID: {}  data_provider: {}  ISUP grade: {}'.format(img_id, \n",
        "                                 df_train[df_train['image_id']==img_id]['data_provider'].values[0],\n",
        "                                 df_train[df_train['image_id']==img_id]['isup_grade'].values[0]))\n",
        "    ax[0].imshow(img)\n",
        "    ax[1].imshow(img_tiles)\n",
        "    ax[2].imshow(mask_tiles, cmap = 'hot', vmin = 0, vmax = 5)\n",
        "    for i in range(3):\n",
        "        ax[i].axis('off')\n",
        "    plt.show()\n",
        "    return\n",
        "    \n",
        "#img_id = df_train[df_train['isup_grade']==3]['image_id'].sample(n=1, random_state = SEED).to_numpy()[0]\n",
        "#plot_tiles_png(img_id)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWDk20uN-qR0",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMDHbbU--qR0",
        "colab_type": "text"
      },
      "source": [
        "Model based on EfficientNetB3:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTNh1I4S-qR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_uncompiled_model():\n",
        "    conv_base = efn.EfficientNetB3(\n",
        "        input_shape = (int(math.sqrt(NUM_TILE))*TILE_SIZE, int(math.sqrt(NUM_TILE))*TILE_SIZE, 3),\n",
        "        weights = 'imagenet', #os.path.join(ENET_MODEL_PATH, \n",
        "                  #'efficientnet-b3_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'),  # pretrained weights with ImageNet\n",
        "        include_top = False,\n",
        "        pooling = 'avg')\n",
        "    conv_base = K.Model(inputs=conv_base.inputs, outputs=conv_base.outputs)\n",
        "    model = Sequential()\n",
        "    model.add(conv_base)\n",
        "    #model.add(K.layers.Dropout(.2))\n",
        "    model.add(K.layers.Dense(6, activation='softmax'))\n",
        "    conv_base.trainable = False\n",
        "    \n",
        "    if restart:\n",
        "        #model.load_weights(restart_path, by_name = True, skip_mismatch = True)\n",
        "        #print('model weights loaded')\n",
        "        # set more layers trainable\n",
        "        conv_base.trainable = True\n",
        "        set_trainable = False\n",
        "        for layer in conv_base.layers:\n",
        "            if layer.name == 'block7b_add':\n",
        "                set_trainable = True\n",
        "            if set_trainable:\n",
        "                layer.trainable = True\n",
        "            else:\n",
        "                layer.trainable = False\n",
        "        model.load_weights(restart_path, by_name = True, skip_mismatch = True)\n",
        "        print('model weights loaded')\n",
        "    else:\n",
        "        print('train from scratch')\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_compiled_model():\n",
        "    model = get_uncompiled_model()\n",
        "    model.compile(\n",
        "        optimizer = K.optimizers.Adam(lr=INI_LR),\n",
        "        loss = tfa.losses.WeightedKappaLoss(num_classes=6, weightage='quadratic'),\n",
        "        metrics = ['categorical_accuracy', tfa.metrics.CohenKappa(num_classes=6, weightage='quadratic')]\n",
        "        )\n",
        "    return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDxb8CxD-qR9",
        "colab_type": "text"
      },
      "source": [
        "## Train the model with KFold cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b1iYLb9M7Rx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2efadbb4-8517-4b7e-c501-4295331b9a99"
      },
      "source": [
        "time_elapsed = time.time() - time_start\n",
        "print('Time elapsed: {:02.0f}:{:02.0f}:{:02.0f} s'.format(time_elapsed//3600,\n",
        "                                                  time_elapsed%3600//60,\n",
        "                                                  time_elapsed%60))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time elapsed: 00:00:03 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfQWLSM-d7lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def kfold_estimate(df, n_fold = N_FOLD, stratefied = True):\n",
        "    if(stratefied):\n",
        "        kf = StratifiedKFold(n_splits = n_fold, random_state = SEED, shuffle = True)\n",
        "    else:\n",
        "        kf = KFold(n_splits = n_fold, random_state = SEED, shuffle = True)\n",
        "    loss_per_fold = []\n",
        "    acc_per_fold = []\n",
        "    kappa_per_fold = []\n",
        "    for i_fold, (train_index, val_index) in enumerate(kf.split(df[['image_id']], df['isup_grade'])):\n",
        "        if(i_fold == 0):  \n",
        "            loss_per_fold.append( -0.7407200336456299)\n",
        "            acc_per_fold.append(0.29909366369247437)\n",
        "            kappa_per_fold.append(0.4803186058998108)\n",
        "            continue\n",
        "        # \n",
        "        print('-------------------------------------------------------------------')\n",
        "        print('Training for fold {} ...'.format(i_fold))\n",
        "        time_kstart = time.time()\n",
        "        model = get_compiled_model()\n",
        "        X_train,  X_val = df.iloc[train_index], df.iloc[val_index]\n",
        "        lbl_value_counts = X_train['isup_grade'].value_counts()\n",
        "        class_weights = {i: max(lbl_value_counts)/v for i, v in lbl_value_counts.items()}\n",
        "        print('classes weights: {}'.format(class_weights))\n",
        "\n",
        "        train_gen = PANDA_tile_Sequence(\n",
        "            df = X_train,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            mode = 'fit',\n",
        "            shuffle = False,\n",
        "            aug = None,\n",
        "            num_tile = NUM_TILE,\n",
        "            tile_size = TILE_SIZE,\n",
        "            n_classes = 6)\n",
        "\n",
        "        val_gen = PANDA_tile_Sequence(\n",
        "            df = X_val,\n",
        "            batch_size = BATCH_SIZE,\n",
        "            mode = 'validate',\n",
        "            shuffle = False,\n",
        "            aug = None,\n",
        "            num_tile = NUM_TILE,\n",
        "            tile_size = TILE_SIZE,\n",
        "            n_classes = 6)\n",
        "\n",
        "        model_file = '{}/model_{}_kf{}.h5'.format(MODEL_PATH, MODEL_VERSION, i_fold)\n",
        "        earlystopper = K.callbacks.EarlyStopping(\n",
        "            monitor = 'val_loss',\n",
        "            patience = 10,\n",
        "            verbose = 1,\n",
        "            mode = 'min'\n",
        "            )\n",
        "        modelsaver = K.callbacks.ModelCheckpoint(\n",
        "            model_file,\n",
        "            monitor = 'val_loss',\n",
        "            verbose = 1,\n",
        "            save_weights_only = True,\n",
        "            save_best_only = True,\n",
        "            mode = 'min'\n",
        "            )\n",
        "        lrreducer = K.callbacks.ReduceLROnPlateau(\n",
        "            monitor = 'val_loss',\n",
        "            factor = .1,\n",
        "            patience = 5,\n",
        "            verbose = 1,\n",
        "            min_lr = 1.e-7\n",
        "            )\n",
        "\n",
        "        history = model.fit(\n",
        "            train_gen,\n",
        "            validation_data = val_gen,\n",
        "            class_weight = class_weights,\n",
        "            callbacks = [earlystopper, modelsaver, lrreducer],\n",
        "            epochs = EPOCHS,\n",
        "            verbose = 1\n",
        "            )\n",
        "\n",
        "        loss_per_fold.append(history.history['val_loss'][-1])\n",
        "        acc_per_fold.append(history.history['val_categorical_accuracy'][-1])\n",
        "        kappa_per_fold.append(history.history['val_cohen_kappa'][-1])\n",
        "        print('Score for fold {}:'.format(i_fold))\n",
        "        print('  loss  {};'.format(loss_per_fold[-1]))\n",
        "        print('  acc   {};'.format(acc_per_fold[-1]))\n",
        "        print('  kappa {}.'.format(kappa_per_fold[-1]))\n",
        "        time_elapsed = time.time() - time_kstart\n",
        "        print('Time elapsed for fold {:4d}: {:02.0f}:{:02.0f}:{:02.0f}'.format(\n",
        "            i_fold, time_elapsed//3600, time_elapsed%3600//60, time_elapsed%60))\n",
        "        mem_usage = memory_profiler.memory_usage(-1)\n",
        "        format_str = 'Memory usage:            ' + '{:8.0f}'*len(mem_usage) + ' MB'\n",
        "        print(format_str.format(*mem_usage))\n",
        "        print('-------------------------------------------------------------------')\n",
        "        del model, X_train, X_val, history\n",
        "        gc.collect()\n",
        "    # Print statistic metrics\n",
        "    print('-------------------------------------------------------------------')\n",
        "    print('Score per fold:')\n",
        "    print('Fold        Loss         Categorical_accuracy            QWK       ')\n",
        "    print('-------------------------------------------------------------------')\n",
        "    for i_fold in range(len(loss_per_fold)):\n",
        "        print('Fold {:4d}    {:12.4f}      {:12.4f}        {:12.4f}'.format(\n",
        "        i_fold, loss_per_fold[i_fold], acc_per_fold[i_fold], kappa_per_fold[i_fold] \n",
        "        ))\n",
        "    print('-------------------------------------------------------------------')\n",
        "    print('Statistical metrics:')\n",
        "    print('Average Loss: {}'.format(np.mean(loss_per_fold)))\n",
        "    print('Accuracy    : {} (+- {})'.format(np.mean(acc_per_fold), np.std(acc_per_fold)))\n",
        "    print('QWK         : {} (+- {})'.format(np.mean(kappa_per_fold), np.std(kappa_per_fold)))\n",
        "    print('-------------------------------------------------------------------')\n",
        "    return"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tu61SwPg-qSC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7aed4065-6e9a-4568-8663-38c281175041"
      },
      "source": [
        "kfold_estimate(df_train)\n",
        "mem_usage = memory_profiler.memory_usage(-1)\n",
        "format_str = 'Memory usage: ' + '{:8.0f}'*len(mem_usage) + ' MB'\n",
        "print(format_str.format(*mem_usage))        "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "model weights loaded\n",
            "classes weights: {0: 1.0, 1: 1.0851703406813626, 2: 2.1552238805970148, 4: 2.3165775401069517, 3: 2.326530612244898, 5: 2.362050163576881}\n",
            "1987/1987 [==============================] - ETA: 0s - loss: -0.9618 - categorical_accuracy: 0.3037 - cohen_kappa: 0.3846\n",
            "Epoch 00001: val_loss improved from inf to -0.73437, saving model to /content/drive/My Drive/Colab Notebooks/competetions/PANDA//model_v1.2_kf1.h5\n",
            "1987/1987 [==============================] - 620s 312ms/step - loss: -0.9618 - categorical_accuracy: 0.3037 - cohen_kappa: 0.3846 - val_loss: -0.7344 - val_categorical_accuracy: 0.3527 - val_cohen_kappa: 0.4847 - lr: 1.0000e-04\n",
            "Score for fold 1:\n",
            "  loss  -0.7343723773956299;\n",
            "  acc   0.3527190387248993;\n",
            "  kappa 0.48471683263778687.\n",
            "Time elapsed for fold    1: 00:10:41\n",
            "Memory usage:         2490 MB\n",
            "-------------------------------------------------------------------\n",
            "-------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "model weights loaded\n",
            "classes weights: {0: 1.0, 1: 1.0851703406813626, 2: 2.1552238805970148, 4: 2.3165775401069517, 3: 2.326530612244898, 5: 2.362050163576881}\n",
            "1987/1987 [==============================] - ETA: 0s - loss: -0.9964 - categorical_accuracy: 0.3125 - cohen_kappa: 0.3997\n",
            "Epoch 00001: val_loss improved from inf to -0.75475, saving model to /content/drive/My Drive/Colab Notebooks/competetions/PANDA//model_v1.2_kf2.h5\n",
            "1987/1987 [==============================] - 611s 308ms/step - loss: -0.9964 - categorical_accuracy: 0.3125 - cohen_kappa: 0.3997 - val_loss: -0.7548 - val_categorical_accuracy: 0.3486 - val_cohen_kappa: 0.4856 - lr: 1.0000e-04\n",
            "Score for fold 2:\n",
            "  loss  -0.7547533512115479;\n",
            "  acc   0.3485649526119232;\n",
            "  kappa 0.4855637550354004.\n",
            "Time elapsed for fold    2: 00:10:33\n",
            "Memory usage:         2647 MB\n",
            "-------------------------------------------------------------------\n",
            "-------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "model weights loaded\n",
            "classes weights: {0: 1.0, 1: 1.0857142857142856, 2: 2.1552238805970148, 4: 2.3141025641025643, 3: 2.326530612244898, 5: 2.362050163576881}\n",
            "1987/1987 [==============================] - ETA: 0s - loss: -0.9763 - categorical_accuracy: 0.3208 - cohen_kappa: 0.3956\n",
            "Epoch 00001: val_loss improved from inf to -0.78671, saving model to /content/drive/My Drive/Colab Notebooks/competetions/PANDA//model_v1.2_kf3.h5\n",
            "1987/1987 [==============================] - 615s 310ms/step - loss: -0.9763 - categorical_accuracy: 0.3208 - cohen_kappa: 0.3956 - val_loss: -0.7867 - val_categorical_accuracy: 0.3705 - val_cohen_kappa: 0.5191 - lr: 1.0000e-04\n",
            "Score for fold 3:\n",
            "  loss  -0.7867105007171631;\n",
            "  acc   0.37046828866004944;\n",
            "  kappa 0.5190737247467041.\n",
            "Time elapsed for fold    3: 00:10:37\n",
            "Memory usage:         2799 MB\n",
            "-------------------------------------------------------------------\n",
            "-------------------------------------------------------------------\n",
            "Score per fold:\n",
            "Fold        Loss         Categorical_accuracy            QWK       \n",
            "-------------------------------------------------------------------\n",
            "Fold    0         -0.7407            0.2991              0.4803\n",
            "Fold    1         -0.7344            0.3527              0.4847\n",
            "Fold    2         -0.7548            0.3486              0.4856\n",
            "Fold    3         -0.7867            0.3705              0.5191\n",
            "-------------------------------------------------------------------\n",
            "Statistical metrics:\n",
            "Average Loss: -0.7541390657424927\n",
            "Accuracy    : 0.3427114859223366 (+- 0.026492304069664966)\n",
            "QWK         : 0.49241822957992554 (+- 0.015517825652523576)\n",
            "-------------------------------------------------------------------\n",
            "Memory usage:     2799 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFfJ6cxA-qSD",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Jw12H8dh14i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_fullset(df):\n",
        "    model = get_compiled_model()\n",
        "    \n",
        "    X_train = df\n",
        "    lbl_value_counts = X_train['isup_grade'].value_counts()\n",
        "    class_weights = {i: max(lbl_value_counts)/v for i, v in lbl_value_counts.items()}\n",
        "    print('classes weights: {}'.format(class_weights))\n",
        "\n",
        "    train_gen = PANDA_tile_Sequence(\n",
        "        df = X_train,\n",
        "        batch_size = BATCH_SIZE,\n",
        "        mode = 'fit',\n",
        "        shuffle = False,\n",
        "        aug = None,\n",
        "        num_tile = NUM_TILE,\n",
        "        tile_size = TILE_SIZE,\n",
        "        n_classes = 6)\n",
        "\n",
        "    model_file = '{}/model_{}.h5'.format(MODEL_PATH, MODEL_VERSION)\n",
        "    earlystopper = K.callbacks.EarlyStopping(\n",
        "        monitor = 'train_loss',\n",
        "        patience = 10,\n",
        "        verbose = 1,\n",
        "        mode = 'min'\n",
        "        )\n",
        "    modelsaver = K.callbacks.ModelCheckpoint(\n",
        "        model_file,\n",
        "        monitor = 'train_loss',\n",
        "        verbose = 1,\n",
        "        save_weights_only = True,\n",
        "        save_best_only = True,\n",
        "        mode = 'min'\n",
        "            )\n",
        "    lrreducer = K.callbacks.ReduceLROnPlateau(\n",
        "        monitor = 'train_loss',\n",
        "        factor = .1,\n",
        "        patience = 5,\n",
        "        verbose = 1,\n",
        "        min_lr = 1.e-7\n",
        "        )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data = None,\n",
        "        class_weight = class_weights,\n",
        "        callbacks = [earlystopper, modelsaver, lrreducer],\n",
        "        epochs = EPOCHS,\n",
        "        verbose = 1\n",
        "        )\n",
        "\n",
        "    history_file = 'history_{}.txt'.format(MODEL_VERSION)\n",
        "    dict_to_save = {}\n",
        "    for k, v in history.history.items():\n",
        "        dict_to_save.update({\n",
        "            k: [np.format_float_positional(x) for x in history.history[k]]\n",
        "        })\n",
        "    with open(history_file, 'w') as file:\n",
        "        json.dump(dict_to_save, file)\n",
        "    ep_max = len(history.history['loss'])\n",
        "    plt.plot(history.history['loss'][:ep_max], label='loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.plot(history.history['categorical_accuracy'][:ep_max], label='accuracy')\n",
        "    plt.plot(history.history['cohen_kappa'][:ep_max], label = 'cohen_kappa')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    del X_train, history\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUUqblkHbOZZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_model():\n",
        "    model = get_compiled_model()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZpHzxjZ-qSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_submit():\n",
        "    df_test = pd.read_csv('{}/test.csv'.format(DATA_PATH))\n",
        "    print(df_test.shape)\n",
        "    pred = np.zeros((len(df_test), 6))\n",
        "    if os.path.exists(TEST_PATH):\n",
        "        sub_gen = PANDA_Sequence(\n",
        "            df = df_test,\n",
        "            batch_size = 1,\n",
        "            mode = 'predict',\n",
        "            shuffle = False,\n",
        "            aug = None,\n",
        "            num_tile = NUM_TILE,\n",
        "            tile_size = TILE_SIZE,\n",
        "            n_classes = 6\n",
        "        )\n",
        "        pred = model.predict(sub_gen)\n",
        "        print('Predict for {} images'.format(len(pred)))\n",
        "    else:\n",
        "        print('Predict zeros')\n",
        "\n",
        "    df_test['isup_grade'] = np.argmax(pred, axis = 1)\n",
        "    df_test.drop('data_provider', axis = 1, inplace = True)\n",
        "    df_test.to_csv('submission.csv', index = False)\n",
        "    print('submission saved')\n",
        "    return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdXWV9NcbOZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "#model = train_fullset(df_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVP1igisbOZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "#model = load_model()\n",
        "#make_submit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3c8BAGv-qSF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!head /kaggle/working/submission.csv"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}